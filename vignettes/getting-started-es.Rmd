---
title: "Primeros pasos con metasurvey (ES)"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Primeros pasos con metasurvey (ES)}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: references.bib
link-citations: true
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE
)
```

## Introduccion

Trabajar con microdatos de encuestas de hogares implica una gran cantidad de
procesamiento repetitivo: recodificar variables categoricas, construir indicadores,
unir datos externos y calcular estimaciones ponderadas. Cada investigador escribe
su propia version de estas transformaciones, y el codigo rara vez se comparte o
documenta de forma que otros puedan reutilizarlo.

**metasurvey** aborda este problema proporcionando una capa de metaprogramacion
sobre el paquete `survey` [@lumley2004]. En lugar de escribir scripts ad hoc,
se construye un **pipeline** de transformaciones que es:

- **Documentado** -- cada paso lleva un comentario, sus variables de
  entrada/salida y sus dependencias
- **Reproducible** -- el pipeline puede guardarse como una receta y aplicarse
  a nuevos datos
- **Compartible** -- las recetas pueden publicarse en una API publica donde
  otros investigadores pueden descubrirlas y reutilizarlas

El pipeline tiene tres niveles:

1. **Steps** -- transformaciones individuales (compute, recode, filter,
   rename, remove, join, validate)
2. **Recipes** -- colecciones reutilizables de steps agrupados con metadatos
3. **Workflows** -- estimaciones estadisticas (`svymean`, `svytotal`,
   `svyby`) que producen las tablas finales

El paquete maneja el survey design ---estratificacion, conglomerados,
pesos replicados--- automaticamente a traves del objeto `Survey`. El usuario
se enfoca en el analisis sustantivo; metasurvey se encarga de la infraestructura.

## Instalacion

```r
# Install from GitHub
devtools::install_github("metaSurveyR/metasurvey")
```

```{r install}
library(metasurvey)
library(data.table)
```

## Creacion de un objeto Survey

Un objeto `Survey` agrupa los microdatos con metadatos sobre pesos, edicion
y tipo de encuesta. Utilizamos una muestra de microdatos reales de la
*Encuesta Continua de Hogares* (ECH) 2023, publicada por el Instituto
Nacional de Estadistica (INE) de Uruguay.

La ECH es una encuesta de hogares de panel rotativo. Las variables clave incluyen:

- **e27**: Edad en anios
- **e26**: Sexo (1 = Hombre, 2 = Mujer)
- **e30**: Parentesco con el jefe de hogar (1-14)
- **POBPCOAC**: Condicion de actividad
  - 1 = Menor de 14
  - 2 = Ocupado
  - 3-5 = Desocupado
  - 6-10 = Inactivo
  - 11 = No aplica
- **HT11**: Ingreso del hogar (pesos uruguayos)
- **W_ANO**: Factor de expansion anual (peso)

```{r create-survey}
library(metasurvey)
library(data.table)

# Cargar muestra de microdatos reales de la ECH 2023 (200 hogares, ~500 personas)
dt <- fread(system.file("extdata", "ech_2023_sample.csv", package = "metasurvey"))

# Crear objeto Survey
svy <- Survey$new(
  data    = dt,
  edition = "2023",
  type    = "ech",
  engine  = "data.table",
  weight  = add_weight(annual = "W_ANO")
)
```

La funcion `add_weight()` mapea etiquetas de periodicidad (por ejemplo, "annual",
"monthly") a los nombres de las columnas de pesos en los datos. Esto permite que
la misma receta funcione con distintas ediciones de la encuesta.

Es posible inspeccionar los datos en cualquier momento:

```{r inspect}
head(get_data(svy), 3)
```

## Trabajo con Steps

Los steps son **lazy por defecto**: se registran pero no se ejecutan hasta que
se llama a `bake_steps()`. Esto permite:

1. Construir un pipeline de transformacion completo
2. Inspeccionar y validar los steps antes de la ejecucion
3. Reutilizar secuencias de steps como recetas
4. Asegurar que todas las dependencias existan antes del procesamiento

### Calculo de nuevas variables

Se utiliza `step_compute()` para crear variables derivadas. El paquete automaticamente:

- Valida que las variables de entrada existan
- Detecta dependencias entre steps
- Optimiza las expresiones para mejorar el rendimiento

```{r step-compute}
svy <- step_compute(svy,
  # Convert income to thousands for readability
  ht11_thousands = HT11 / 1000,

  # Create employment indicator following ILO definitions
  employed = ifelse(POBPCOAC == 2, 1, 0),

  # Working age population (14+ years, ECH standard)
  working_age = ifelse(e27 >= 14, 1, 0),
  comment = "Basic labor force indicators"
)
```

Es posible agrupar calculos usando el parametro `.by` (similar a `data.table`):

```{r step-compute-grouped}
# Calculate mean household income per department
svy <- step_compute(svy,
  mean_income_dept = mean(HT11, na.rm = TRUE),
  .by = "dpto",
  comment = "Department-level income averages"
)
```

### Recodificacion en categorias

Se utiliza `step_recode()` para crear variables categoricas a partir de condiciones.
Las condiciones se evaluan **de arriba hacia abajo**, y la primera coincidencia es
la que se aplica.

```{r step-recode}
# Recode labor force status (POBPCOAC) into meaningful categories
svy <- step_recode(svy, labor_status,
  POBPCOAC == 2 ~ "Employed",
  POBPCOAC %in% 3:5 ~ "Unemployed",
  POBPCOAC %in% 6:10 ~ "Inactive",
  .default = "Not classified",
  comment = "Labor force status - ILO standard"
)

# Create standard age groups for labor statistics
svy <- step_recode(svy, age_group,
  e27 < 25 ~ "Youth (14-24)",
  e27 < 45 ~ "Adult (25-44)",
  e27 < 65 ~ "Mature (45-64)",
  .default = "Elderly (65+)",
  .to_factor = TRUE, # Convert to factor
  ordered = TRUE, # Ordered factor
  comment = "Age groups for labor analysis"
)

# Recode sex into descriptive labels
svy <- step_recode(svy, gender,
  e26 == 1 ~ "Male",
  e26 == 2 ~ "Female",
  .default = "Other",
  comment = "Gender classification"
)
```

### Filtrado de filas

Se utiliza `step_filter()` para seleccionar filas segun condiciones logicas.
Multiples condiciones se combinan con AND. Al igual que los demas steps,
los filtros son lazy por defecto.

```{r step-filter}
# Mantener solo individuos en edad de trabajar (14+)
svy <- step_filter(svy,
  e27 >= 14,
  comment = "Working-age population only"
)
```

### Renombrar y eliminar variables

Se renombran variables para mayor claridad o consistencia:

```{r step-rename}
svy <- step_rename(svy,
  age = e27, # Rename e27 to age
  sex_code = e26 # Keep original as sex_code
)
```

Se eliminan variables que ya no son necesarias:

```{r step-remove}
# Remove intermediate calculations
svy <- step_remove(svy, working_age, mean_income_dept)
```

### Union con datos externos

Se utiliza `step_join()` para unir datos de referencia externos. Esto es util para agregar:

- Nombres y clasificaciones geograficas
- Tipos de cambio o deflactores
- Benchmarks o metas externas

Los microdatos reales de la ECH ya incluyen `nom_dpto` y `region`.
Aqui demostramos un join con lineas de pobreza como ejemplo:

```{r step-join}
# Lineas de pobreza por region (valores ilustrativos en UYU, 2023)
poverty_lines <- data.table(
  region = 1:3,
  poverty_line = c(19000, 12500, 11000),
  region_name = c("Montevideo", "Interior loc. >= 5000", "Interior loc. < 5000")
)

svy <- step_join(svy,
  poverty_lines,
  by = "region",
  type = "left",
  comment = "Add poverty lines by region"
)
```

## Ejecucion de transformaciones

### Aplicacion de steps (bake)

Se llama a `bake_steps()` para ejecutar todas las transformaciones pendientes:

```{r bake}
svy <- bake_steps(svy)
head(get_data(svy), 3)
```

El historial de steps se preserva para documentacion y reproducibilidad:

```{r get-steps}
steps <- get_steps(svy)
length(steps) # Number of transformation steps

# View step details
cat("Step 1:", steps[[1]]$name, "\n")
cat("Comment:", steps[[1]]$comment, "\n")
```

### Visualizacion del pipeline

Es posible visualizar el pipeline de transformacion como un grafo dirigido:

```{r view-graph, eval = requireNamespace("visNetwork", quietly = TRUE)}
view_graph(svy, init_step = "Load ECH 2023")
```

Esto genera un grafo interactivo que muestra:

- Fuentes de datos y uniones
- Steps de transformacion
- Dependencias entre variables
- Comentarios y metadatos

## Estimaciones estadisticas

Una vez preparados los datos, se utiliza `workflow()` para calcular estimaciones
de encuesta. La funcion envuelve los estimadores del paquete `survey` [@lumley2004]
y devuelve resultados ordenados con errores estandar y coeficientes de variacion.

**Importante:** Se debe pasar el objeto survey dentro de un `list()`.

### Estimaciones basicas

```{r workflow-mean}
# Estimate mean household income
result <- workflow(
  list(svy),
  survey::svymean(~HT11, na.rm = TRUE),
  estimation_type = "annual"
)

result
```

La salida incluye:

- `estimate`: Estimacion puntual
- `se`: Error estandar
- `cv`: Coeficiente de variacion
- `var_name`: Nombre de la variable
- `level`: Nivel del factor (para variables categoricas)

### Estimaciones multiples

Es posible calcular varias estadisticas en una sola llamada:

```{r workflow-multi}
results <- workflow(
  list(svy),
  survey::svymean(~HT11, na.rm = TRUE), # Mean income
  survey::svytotal(~employed, na.rm = TRUE), # Total employed
  survey::svymean(~labor_status, na.rm = TRUE), # Employment distribution
  estimation_type = "annual"
)

results
```

### Estimacion por dominios

Se calculan estimaciones para subpoblaciones usando `survey::svyby()`:

```{r workflow-domain}
# Mean income by gender
income_by_gender <- workflow(
  list(svy),
  survey::svyby(~HT11, ~gender, survey::svymean, na.rm = TRUE),
  estimation_type = "annual"
)

income_by_gender
```

## Evaluacion de calidad

El **coeficiente de variacion (CV)** mide la confiabilidad de las estimaciones.
Un CV mas bajo indica estimaciones mas precisas. Siguiendo las pautas del
INE Uruguay [@ine2023]:

| Rango de CV | Categoria de calidad | Recomendacion |
|-------------|----------------------|---------------|
| < 5%        | Excelente            | Usar sin restricciones |
| 5%--10%     | Muy buena            | Usar con confianza |
| 10%--15%    | Buena                | Usar para la mayoria de los propositos |
| 15%--25%    | Aceptable            | Usar con precaucion, senialando limitaciones |
| 25%--35%    | Pobre                | Usar solo para tendencias generales |
| >= 35%      | No confiable         | No publicar |

Se utiliza `evaluate_cv()` para clasificar la calidad de las estimaciones:

```{r cv}
# Check quality of mean income estimate
cv_percentage <- results$cv[1] * 100
quality <- evaluate_cv(cv_percentage)

cat("CV:", round(cv_percentage, 2), "%\n")
cat("Quality:", quality, "\n")
```

Para estadisticas oficiales, siempre se debe reportar:

1. Estimacion puntual
2. Error estandar o intervalo de confianza
3. Coeficiente de variacion
4. Clasificacion de calidad
5. Tamanio de la muestra

## Trabajo con Recipes

Las recipes agrupan steps de transformacion para **reproducibilidad** y
**comparticion**. Una vez desarrollado un pipeline funcional, se puede convertir
en una receta que puede ser:

- Aplicada a diferentes ediciones de la encuesta
- Compartida con colaboradores
- Publicada para garantizar transparencia
- Versionada y documentada

### Creacion de una Recipe

Se crea una receta a partir de los steps desarrollados:

```{r recipe-create}
# Convert current steps to a recipe
labor_recipe <- steps_to_recipe(
  name = "ECH Labor Force Indicators",
  user = "National Statistics Office",
  svy = svy,
  description = paste(
    "Standard labor force indicators following ILO definitions.",
    "Creates employment status, age groups, and gender classifications."
  ),
  steps = get_steps(svy),
  topic = "labor_statistics"
)

class(labor_recipe)
labor_recipe$name
```

O se puede definir una receta desde cero:

```r
minimal_recipe <- recipe(
  name = "Basic Demographics - ECH",
  user = "analyst",
  svy = survey_empty(type = "ech", edition = "2023"),
  description = "Basic demographic recoding for ECH microdata",
  topic = "demographics",

  # Define steps inline
  step_recode(
    gender,
    e26 == 1 ~ "Male",
    e26 == 2 ~ "Female",
    .default = "Other"
  ),
  step_recode(
    age_group,
    e27 < 14 ~ "Child",
    e27 < 65 ~ "Adult",
    .default = "Senior"
  )
)
```

### Aplicacion de Recipes a nuevos datos

Una vez publicada, cualquier persona puede recuperar una receta por ID y aplicarla a sus datos:

```r
# Obtener una receta por ID desde la API (requiere servidor)
r <- api_get_recipe("ech_labor_001")

# Aplicar a una nueva encuesta
new_svy <- add_recipe(new_svy, r)
processed <- bake_recipes(new_svy)
```

### Documentacion de Recipes

Las recetas documentan automaticamente sus transformaciones:

```{r recipe-doc}
doc <- labor_recipe$doc()
names(doc)

# Input variables required
doc$input_variables

# Output variables created
doc$output_variables
```

## Configuracion del paquete

metasurvey ofrece configuraciones globales que se pueden ajustar segun el flujo de trabajo:

```{r config}
# Check current lazy-processing setting
lazy_default() # TRUE = steps recorded but not executed immediately

# Check data-copy behavior
use_copy_default() # TRUE = operate on copies (safer but slower)

# View available computation engines
show_engines() # "data.table", "dplyr", etc.
```

Se pueden modificar las configuraciones para la sesion actual:

```{r config-set}
# Disable lazy evaluation (execute steps immediately)
set_lazy_processing(FALSE)

# Modify inplace (faster, but modifies original data)
set_use_copy(FALSE)

# Reset to defaults
set_lazy_processing(TRUE)
set_use_copy(TRUE)
```

## Compartir el trabajo: el ecosistema de recipes

Uno de los objetivos de metasurvey es reducir el esfuerzo duplicado en la
comunidad de investigadores que trabajan con encuestas. Si se ha construido un
pipeline de procesamiento util, es posible publicarlo para que otros lo encuentren
y reutilicen. El paquete se conecta a una API publica donde se almacenan recipes
y workflows:

```r
# Buscar recipes existentes (requiere servidor API)
ech_recipes <- api_list_recipes(survey_type = "ech")
length(ech_recipes)

# Buscar algo especifico
labor <- api_list_recipes(search = "labor")

# Para publicar, crear una cuenta primero
api_register("Your Name", "you@example.com", "password")

# Luego publicar
api_publish_recipe(labor_recipe)
```

El ecosistema soporta tres niveles de certificacion (comunitaria, revisada,
oficial) y tres tipos de cuenta (individual, miembro institucional,
institucion). Las cuentas institucionales requieren aprobacion de un
administrador, lo que asegura que las certificaciones tengan respaldo real.

Para mas detalles, consultar [Creacion y comparticion de Recipes](recipes.html).

## Datos y agradecimientos

Los datos de ejemplo utilizados en esta vinieta provienen de la *Encuesta
Continua de Hogares* (ECH) 2023, publicada por el Instituto Nacional de
Estadistica (INE) de Uruguay. Los microdatos completos estan disponibles en
[INE](https://www.gub.uy/instituto-nacional-estadistica/).

El paquete **[ech](https://calcita.github.io/ech/)** de Gabriela Mathieu
y Richard Detomasi fue una inspiracion importante para metasurvey. Mientras
que `ech` provee funciones listas para usar para calcular indicadores
socioeconomicos, metasurvey toma un enfoque diferente: proporciona una capa
de metaprogramacion que permite a los usuarios definir, compartir y
reproducir sus propios pipelines de procesamiento.

## Paquetes relacionados

metasurvey es parte de un ecosistema creciente de paquetes de R para el
analisis de encuestas de hogares en America Latina:

- **[ech](https://calcita.github.io/ech/)** -- Funciones para el calculo de
  indicadores socioeconomicos con la ECH de Uruguay (Mathieu & Detomasi).
  Provee funciones listas para usar sobre pobreza, ingresos, educacion e
  indicadores de empleo.
- **[eph](https://docs.ropensci.org/eph/)** -- Herramientas para trabajar con
  la Encuesta Permanente de Hogares de Argentina. Publicado en rOpenSci.
  Cubre descarga de datos, construccion de paneles y calculo de pobreza.
- **[survey](https://cran.r-project.org/package=survey)** -- El paquete
  fundamental para inferencia basada en disenio con encuestas complejas
  [@lumley2004]. metasurvey se construye sobre el.

## Proximos pasos

Ahora que se comprenden los conceptos basicos, se pueden explorar estas guias:

- **[Creacion y comparticion de Recipes](recipes.html)** -- Registro de recipes, certificacion y descubrimiento
- **[Workflows de estimacion](workflows-and-estimation.html)** -- `workflow()`, `RecipeWorkflow` y estimaciones publicables
- **[Survey designs y validacion](complex-designs.html)** -- Estratificacion, conglomerados, pesos replicados, validacion del pipeline
- **[Paneles rotativos y PoolSurvey](panel-analysis.html)** -- Analisis longitudinal con `RotativePanelSurvey` y `PoolSurvey`
- **[Caso de estudio ECH](ech-case-study.html)** -- Analisis completo del mercado laboral con comparacion con STATA

## Referencias
